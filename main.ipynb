{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-visibility",
   "metadata": {},
   "source": [
    "# Bank account fraud detection\n",
    "Daniel Mizrahi (10675418), Antonio La Chira Marquina (11847018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from data_analysis import *\n",
    "from read_data import read_dataset\n",
    "from classifiers import *\n",
    "from performance import *\n",
    "\n",
    "\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-impossible",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "We first start off by reading in the data. Since some of the data is categorical and therefore non-numerical we must use one hot encoding to process the data and make sure this won't be a problem when implenting our classifiers such logistic regression. Altough perhaps marginal when converting categorical data we drop the first column so there is less data later on to perform calculations on. The original data without one hot encoding can be used to perform analysis and make conclusions about the data and for Naive Bayes classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import read_dataset\n",
    "\n",
    "data_original = read_dataset('datasets/Base.csv', process=False)\n",
    "data = read_dataset('datasets/Base.csv', process=True, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preview of the one hot encoded data in table form (first 10 rows and 4 columns):')\n",
    "print(data.head(10).iloc[:, :4])\n",
    "\n",
    "print(f'\\nOrignal data shape (rows, columns): {data_original.shape}')\n",
    "print(f'One hot encoded data shape (rows, columns): {data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-childhood",
   "metadata": {},
   "source": [
    "## Visualization of data\n",
    "### Visualization of all data\n",
    "We visualize the raw (original) dataset by plotting histograms and bar charts for each column in the dataframe.\n",
    "Note that this is all the data, no distinction has been made yet in fraudulent vs non-fraudulent data.\n",
    "Since there are essentially three types of information in the dataset we split the data into categorical data, boolean data and other (continuous?) data and adjust the plot for each type accordingly.\n",
    "\n",
    "This visualization allows us to speculate about the possible underlying distributions for the data by column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-smoke",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# k = 'auto'\n",
    "k = 100\n",
    "\n",
    "categorical_data = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "boolean_data = ['fraud_bool', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards',\n",
    "                'foreign_request', 'keep_alive_session', 'device_fraud_count']\n",
    "\n",
    "fig, axs = plt.subplots(16, 2, figsize=(16,100))\n",
    "column_names = list(data_original.columns.values)\n",
    "for column, ax in enumerate(axs.flat):\n",
    "    ax.set_xlabel(column_names[column])\n",
    "    ax.set_ylabel('Count')\n",
    "    if column_names[column] in boolean_data:\n",
    "        labels, counts = np.unique(data_original.iloc[:, column], return_counts=True)\n",
    "        ax.bar(labels, counts, width=1)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(['False', 'True'])\n",
    "    elif column_names[column] in categorical_data:\n",
    "        labels, counts = np.unique(data_original.iloc[:, column], return_counts=True)\n",
    "        ax.bar(labels, counts)\n",
    "    else:\n",
    "        unique_values = data_original.iloc[:, column].unique().size\n",
    "        ax.hist(data_original.iloc[:, column], unique_values if unique_values < k else k)\n",
    "    if column_names[column] not in categorical_data + boolean_data:\n",
    "        mean = np.mean(data_original.iloc[:, column])\n",
    "        standard_deviation = np.std(data_original.iloc[:, column])\n",
    "        ax.axvline(mean, color='y')\n",
    "        if mean - standard_deviation > np.amin(data_original.iloc[:, column]):\n",
    "            ax.axvline(mean - standard_deviation, color='r')\n",
    "        ax.axvline(mean + standard_deviation, color='r')\n",
    "        ax.legend([f'mean (approx {round(mean, 2)})', f'standard deviation (approx {round(standard_deviation, 2)})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-premiere",
   "metadata": {},
   "source": [
    "### Visualization of data seperated by fraud and non fraud\n",
    "We create histograms/bar charts for all columns in the dataframe similar to what we did previously except for these plots we separate the data by fraudulent and non-fraudulent data. Additionally the histograms/bar charts are normalized by the number of rows.\n",
    "\n",
    "The normalization in this case is important because the number of non-fraudulent data entries is about 980k which is much larger than the number of fraudulent data entries which is roughly 20k. Normalization allows us to better compare the behaviours of the underlying distributions per category.\n",
    "\n",
    "This visualization allows us to speculate about the differences between fraudulent/non-fraudulent entries and all other parameters such as 'fraud vs credit risk score' and 'no fraud vs credit risk score'. Visual inspection alone already shows in some cases the distributions of fraud and non fraud can be quite different. Others not so much but further analysis might show different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-bradford",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# k = 'auto'\n",
    "k = 100\n",
    "\n",
    "categorical_data = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "boolean_data = ['fraud_bool', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards',\n",
    "                'foreign_request', 'keep_alive_session', 'device_fraud_count']\n",
    "\n",
    "data_fraud = data_original.loc[data_original['fraud_bool'] == 1]\n",
    "data_no_fraud = data_original.loc[data_original['fraud_bool'] == 0]\n",
    "\n",
    "fig, axs = plt.subplots(16, 2, figsize=(16,100))\n",
    "column_names = list(data_original.columns.values)\n",
    "for column, ax in enumerate(axs.flat):\n",
    "    ax.set_xlabel(column_names[column])\n",
    "    ax.set_ylabel('Count (normalized)')\n",
    "    if column_names[column] in boolean_data:\n",
    "        lbls_f, cts_f = np.unique(data_fraud.iloc[:, column], return_counts=True)\n",
    "        lbls_nf, cts_nf = np.unique(data_no_fraud.iloc[:, column], return_counts=True)\n",
    "        ax.bar(lbls_f, cts_f / len(data_fraud.iloc[:, column]), width=1, label='Fraud', alpha=.6)\n",
    "        ax.bar(lbls_nf, cts_nf / len(data_no_fraud.iloc[:, column]), width=1, label='No fraud', alpha=.6)\n",
    "        ax.set_xticks([0, 1])\n",
    "        ax.set_xticklabels(['False', 'True'])\n",
    "    elif column_names[column] in categorical_data:\n",
    "        lbls_f, cts_f = np.unique(data_fraud.iloc[:, column], return_counts=True)\n",
    "        lbls_nf, cts_nf = np.unique(data_no_fraud.iloc[:, column], return_counts=True)\n",
    "        ax.bar(lbls_f, cts_f / len(data_fraud.iloc[:, column]), label='Fraud', alpha=.6)\n",
    "        ax.bar(lbls_nf, cts_nf / len(data_no_fraud.iloc[:, column]), label='No fraud', alpha=.6)\n",
    "    else:\n",
    "        unique_values = len(set(data_fraud.iloc[:, column].unique()) | set(data_no_fraud.iloc[:, column].unique()))\n",
    "        ax.hist(data_fraud.iloc[:, column], unique_values if unique_values < k else k, label='Fraud', density=True, alpha=.6)\n",
    "        ax.hist(data_no_fraud.iloc[:, column], unique_values if unique_values < k else k, label='No fraud', density=True, alpha=.6)\n",
    "    ax.legend()\n",
    "    if column_names[column] not in categorical_data + boolean_data:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        mean_f = np.mean(data_fraud.iloc[:, column])\n",
    "        mean_nf = np.mean(data_no_fraud.iloc[:, column])\n",
    "        mn_f = ax.axvline(mean_f, color='g')\n",
    "        mn_nf = ax.axvline(mean_nf, color='k')\n",
    "        ax.legend(handles + [mn_f, mn_nf], labels + [f'mean fraud (approx {round(mean_f, 2)})', f'mean no fraud(approx {round(mean_nf, 2)})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-triple",
   "metadata": {},
   "source": [
    "## Similarity and differences of variables between fraudulent and nonfraudulent\n",
    "### Bootstrap test for mean and standard deviation\n",
    "Altough as mentioned visual inspection alone already shows a distribution between fraud and non fraud can be quite different other seems not so much. By bootstrapping random values of every variable to create a dataset of the same size as the fraud dataset we can show how significant the distributions differ are by already only looking at the mean and standard deviation. Plots also include CI's for $\\alpha = 5$ and is one-tailed (direction will be clear in the plots). Almost all have $p$-values of $0.0$.\n",
    "\n",
    "The hypothesis is then: \\\n",
    "$H_0$: The mean and/or standard deviation of a fraudulent dataset is equal* tot a nonfraudulent dataset\n",
    "\n",
    "\\* As explained before the test is one tailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-denmark",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_fraud = data_original.loc[data_original['fraud_bool'] == 1]\n",
    "size = data_fraud.shape[0]\n",
    "iterations = 10000\n",
    "categorical_data = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "boolean_data = ['fraud_bool', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards',\n",
    "                'foreign_request', 'keep_alive_session', 'device_fraud_count']\n",
    "columns_exclude = categorical_data + boolean_data\n",
    "test = bootstrap_mean_standard_deviation(data_original, data_fraud, size, iterations, columns_exclude=columns_exclude)\n",
    "\n",
    "k = 50\n",
    "fig, axs = plt.subplots(len(test), 2, figsize=(16,100))\n",
    "for column, ax in enumerate(axs.flat):\n",
    "    ax.set_xlabel(test[int(column / 2)][0] + (' standard deviation' if column % 2 else ' mean'))\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.hist(test[int(column / 2)][1 + column % 2], k)\n",
    "    fraud_statistic = data_fraud[test[int(column / 2)][0]].std() if column % 2 else data_fraud[test[int(column / 2)][0]].mean()\n",
    "    bootstrap_mean = np.mean(test[int(column / 2)][1 + column % 2])\n",
    "     confidence_intervals = np.percentile(test[int(column / 2)][1 + column % 2], [2.5, 97.5])\n",
    "    ax.axvline(fraud_statistic, color='g')\n",
    "    ax.axvline(bootstrap_mean, color='r')\n",
    "    ax.axvline(confidence_intervals[0], color='y')\n",
    "    ax.axvline(confidence_intervals[1], color='y')\n",
    "    ax.legend([f'Fraud (approx {round(fraud_statistic, 2)}, $p$-value {test[int(column / 2)][3 + column % 2]})',\n",
    "               f'Bootstrap mean (aprrox {round(bootstrap_mean, 2)})',\n",
    "               f'CI at 2.5 and 97.5% (aprrox {round(confidence_intervals[0], 2)} and {round(confidence_intervals[1], 2)})'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-layout",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov and Epps-Singleton test for distribution similarity\n",
    "By using the Kolmogorov-Smirnov we can calculate how similar two samples are. Note that the two-sample test checks whether the two data samples come from the same distribution. This does not specify what that common distribution is (e.g. whether it's normal or not normal). The test gives us a KS-statistic (1.0 means complete dissimilarity and 0.0 complete similarity) and a $p$-value.\n",
    "\n",
    "The Epps-Singleton test also calculates how similar two samples are. The test gives us a ES-statistic (lower means more similar) and a $p$-value.\n",
    "\n",
    "If we choose $\\alpha = 0.05$ no two distributions fraud and non fraud are similar enough to be considered drawn from the same distribution.\n",
    "\n",
    "In both cases the hypothesis is: \\\n",
    "$H_0$: The 2 samples are drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_data = ['income', 'name_email_similarity', 'prev_address_months_count', 'current_address_months_count',\n",
    "                   'days_since_request', 'intended_balcon_amount', 'zip_count_4w', 'velocity_6h', 'velocity_24h',\n",
    "                   'velocity_4w', 'bank_branch_count_8w', 'credit_risk_score', 'bank_months_count',\n",
    "                   'session_length_in_minutes']\n",
    "\n",
    "data_fraud = data.loc[data['fraud_bool'] == 1]\n",
    "data_no_fraud = data.loc[data['fraud_bool'] == 0]\n",
    "\n",
    "ks_statistics = kolmogorov_smirnov_similarity(data_fraud[continuous_data], data_no_fraud[continuous_data])\n",
    "ep_statistics = epps_singleton_similarity(data_fraud[continuous_data], data_no_fraud[continuous_data])\n",
    "ks_most_similar = np.argsort(ks_statistics[:, 0])\n",
    "ep_most_similar = np.argsort(ep_statistics[:, 0])\n",
    "\n",
    "ks_table = list()\n",
    "for column in ks_most_similar:\n",
    "    ks_table.append([data[continuous_data].columns[column], ks_statistics[column][0], ks_statistics[column][1]])\n",
    "print(pd.DataFrame(ks_table, columns=['Variable', 'KS statistic', 'p-value']))\n",
    "print()\n",
    "\n",
    "ep_table = list()\n",
    "for column in ep_most_similar:\n",
    "    ep_table.append([data[continuous_data].columns[column], ep_statistics[column][0], ep_statistics[column][1]])\n",
    "print(pd.DataFrame(ep_table, columns=['Variable', 'EP statistic', 'p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-firmware",
   "metadata": {},
   "source": [
    "### Pearson and Spearman correlation\n",
    "By calculating Pearson and Spearman correlations between the variables and especially bool_fraud and the rest. We could possibly determine which variables are more relevant for it to be fraudulent. It should be noted that pearson correlation is sensitive to non normal data. Data which later on will be shown that almost all are non normal. So statistics generated by Pearson should be taken with a grain of salt. Also Spearman also takes nonlinear correlation into consideration. The $p$-values of Pearson is also influenced by normality so we will ignore that. Spearman's $p$-value on the otherhand expresses the chance both samples are uncorrelated.\n",
    "\n",
    "So the hypothesis for Spearman is: \\\n",
    "$H_0$: The two sets of data are uncorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "pearson_correlations = pearson_correlation_coefficient(data)\n",
    "spearman_correlations = spearman_correlation_coefficient(data)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(24,40))\n",
    "\n",
    "hm_p = ax[0].imshow(np.array(pearson_correlations), cmap=plt.cm.rainbow)\n",
    "hm_s = ax[1].imshow(np.array(spearman_correlations), cmap=plt.cm.rainbow)\n",
    "\n",
    "ax[0].set_title('Heatmap of pearson correlations between all parameters', fontsize=20)\n",
    "ax[0].set_xticks(np.arange(len(data.columns)))\n",
    "ax[0].set_yticks(np.arange(len(data.columns)))\n",
    "\n",
    "ax[0].set_xticklabels(data.columns, rotation=90)\n",
    "ax[0].set_yticklabels(data.columns)\n",
    "\n",
    "ax[1].set_title('Heatmap of spearman correlations between all parameters', fontsize=20)\n",
    "ax[1].set_xticks(np.arange(len(data.columns)))\n",
    "ax[1].set_yticks(np.arange(len(data.columns)))\n",
    "\n",
    "ax[1].set_xticklabels(data.columns, rotation=90)\n",
    "ax[1].set_yticklabels(data.columns)\n",
    "\n",
    "# Add axes underneath both subplots\n",
    "div1 = make_axes_locatable(ax[0])\n",
    "div2 = make_axes_locatable(ax[1])\n",
    "\n",
    "cax1 = div1.new_vertical(size='5%', pad=2.5, pack_start=True)\n",
    "cax2 = div2.new_vertical(size='5%', pad=2.5, pack_start=True)\n",
    "\n",
    "fig.add_axes(cax1)\n",
    "fig.add_axes(cax2)\n",
    "\n",
    "fig.colorbar(hm_p, cax=cax1, orientation='horizontal')\n",
    "fig.colorbar(hm_s, cax=cax2, orientation='horizontal')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "pearson_table = list()\n",
    "spearman_table = list()\n",
    "for column in data.columns:\n",
    "    pearson_correlations = pearson_correlation_coefficient(np.array(data['fraud_bool']), np.array(data[column]))\n",
    "    spearman_correlations = spearman_correlation_coefficient(np.array(data['fraud_bool']), np.array(data[column]))\n",
    "    pearson_table.append([column, pearson_correlations[0], pearson_correlations[1]])\n",
    "    spearman_table.append([column, spearman_correlations[0], spearman_correlations[1]])\n",
    "print(pd.DataFrame(pearson_table, columns=['Variable', 'Pearson', 'p-value']))\n",
    "print()\n",
    "print(pd.DataFrame(spearman_table, columns=['Variable', 'Spearman', 'p-value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-stanley",
   "metadata": {},
   "source": [
    "## Fitting distributions\n",
    "By fitting types distributions we can further our understanding of the data. Just assuming everything is normal will not suffice. Also this information can be used to build a better Naive Bayes implementation than the one provided by for example sklearn. A number of distributions are tried using MLE. $p$-values are generated for every fit using the Kolmogor-Smirnov test and the best one is plotted (the best fit can still have a $p$ value of around $0.0$).\n",
    "\n",
    "The null hypothesis is then: \\\n",
    "$H_0$: The data is drawn from distribution X*\n",
    "\n",
    "\\* The distribution is shown in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-questionnaire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical_data = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "boolean_data = ['fraud_bool', 'email_is_free', 'phone_home_valid', 'phone_mobile_valid', 'has_other_cards',\n",
    "                'foreign_request', 'keep_alive_session', 'device_fraud_count']\n",
    "\n",
    "data_fraud = data_original.loc[data_original['fraud_bool'] == 1]\n",
    "data_no_fraud = data_original.loc[data_original['fraud_bool'] == 0]\n",
    "\n",
    "distribution_consider = ['alpha', 'beta', 'cosine', 'gamma', 'pareto', 'rayleigh', 'norm', 'lognorm', 'dweibull']\n",
    "\n",
    "continuous_data = list()\n",
    "for column in data_original.columns:\n",
    "    if data_original[column].nunique() >= 3 and data_original[column].dtypes != object:\n",
    "        continuous_data.append(column)\n",
    "\n",
    "k = 50\n",
    "fig, axs = plt.subplots(int(len(continuous_data) / 2) + 1, 2, figsize=(16,100))\n",
    "for column, ax in enumerate(axs.flat):\n",
    "    ax.set_xlabel(data_original[continuous_data].columns[column])\n",
    "    ax.set_ylabel('Count (normalized)')\n",
    "    ax.hist(data_original[continuous_data].iloc[:, column], k, density=True)\n",
    "    best_distribution = find_distribution(data_original[continuous_data].iloc[:, column])\n",
    "    x = np.linspace(np.amin(data_original[continuous_data].iloc[:, column]),\n",
    "                    np.amax(data_original[continuous_data].iloc[:, column]), 1000)\n",
    "    args = best_distribution[1][:-2]\n",
    "    y = None\n",
    "    if args:\n",
    "        y = getattr(stats, best_distribution[0]).pdf(x, *args, loc=best_distribution[1][-2],\n",
    "                                                     scale=best_distribution[1][-1])\n",
    "    else:\n",
    "        y = getattr(stats, best_distribution[0]).pdf(x, loc=best_distribution[1][-2],\n",
    "                                                     scale=best_distribution[1][-1])\n",
    "    ax.plot(x, y, color='r')\n",
    "    ax.legend([f'{best_distribution[0]} $p$-value {best_distribution[2][1]}', 'Sample'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-welsh",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_data = list()\n",
    "for column in data_original.columns:\n",
    "    if data_original[column].nunique() >= 3 and data_original[column].dtypes != object:\n",
    "        continuous_data.append(column)\n",
    "continuous_data = ['fraud_bool'] + continuous_data\n",
    "\n",
    "precisions = list()\n",
    "recalls = list()\n",
    "accuracies = list()\n",
    "f1s = list()\n",
    "iterations = 1000\n",
    "for _ in range(iterations):\n",
    "    i_row_train = np.random.choice(data_original[continuous_data].shape[0],\n",
    "                               data_original[continuous_data].shape[0] * 70 // 100, replace=False)\n",
    "    i_row_test = np.array(list(set(np.arange(data_original[continuous_data].shape[0])) - set(i_row_train)))\n",
    "    target_sample = data_original[continuous_data].values[i_row_train, 0]\n",
    "    train_sample = data_original[continuous_data].values[i_row_train, 1:]\n",
    "    test_sample = data_original[continuous_data].values[i_row_test, 1:]\n",
    "    test_target = data_original[continuous_data].values[i_row_test, 0]\n",
    "    clf_nb = NaiveBayesClassifier()\n",
    "    clf_nb.fit(train_sample, target_sample)\n",
    "    test_prediction = clf_nb.predict(test_sample)\n",
    "    precisions.append(precision_score(test_target, test_prediction))\n",
    "    recalls.append(recall_score(test_target, test_prediction))\n",
    "    accuracies.append(accuracy_score(test_target, test_prediction))\n",
    "    f1s.append(f1_score(test_target, test_prediction))\n",
    "scores = [precisions, recalls, accuracies, f1s]\n",
    "\n",
    "i_row_train = np.random.choice(data_original[continuous_data].shape[0],\n",
    "                               data_original[continuous_data].shape[0] * 70 // 100, replace=False)\n",
    "i_row_test = np.array(list(set(np.arange(data_original[continuous_data].shape[0])) - set(i_row_train)))\n",
    "target_sample = data_original[continuous_data].values[i_row_train, 0]\n",
    "train_sample = data_original[continuous_data].values[i_row_train, 1:]\n",
    "test_sample = data_original[continuous_data].values[i_row_test, 1:]\n",
    "test_target = data_original[continuous_data].values[i_row_test, 0]\n",
    "clf_mnb = MultiNaiveBayesClassifier()\n",
    "clf_mnb.fit(train_sample, target_sample)\n",
    "multi_test_prediction = clf_nb.predict(test_sample)\n",
    "\n",
    "multi_precision = precision_score(test_target, test_prediction)\n",
    "multi_recall = recall_score(test_target, test_prediction)\n",
    "multi_accuracy = accuracy_score(test_target, test_prediction)\n",
    "multi_f1 = f1_score(test_target, test_prediction)\n",
    "scores_multi = [multi_precision, multi_recall, multi_accuracy, multi_f1]\n",
    "score_names = ['Precision', 'Recall', 'Accuracy', 'F1']\n",
    "k = 50\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16,100))\n",
    "for score, ax in enumerate(axs.flat):\n",
    "    ax.set_xlabel(score_names[score])\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.hist(scores[score], k)\n",
    "    bootstrap_mean = np.mean(scores[score])\n",
    "    confidence_interval = np.percentile(scores[score], 95)\n",
    "    p_value = np.count_nonzero(np.array(scores[score]) < scores_multi[score]) / iterations\n",
    "    ax.axvline(scores_multi[score], color='g')\n",
    "    ax.axvline(bootstrap_mean, color='r')\n",
    "    ax.axvline(confidence_interval, color='y')\n",
    "    ax.legend([f'Multi NB (approx {round(scores_multi[score], 2)}, $p$-value {p_value})',\n",
    "               f'Bootstrap mean (aprrox {round(bootstrap_mean, 2)})',\n",
    "               f'CI at 95% (aprrox {round(confidence_interval, 2)}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "tf = Normalizer()\n",
    "\n",
    "# Select strongest correlation parameters (positive)\n",
    "params = ['fraud_bool', 'device_os_windows', 'credit_risk_score', 'proposed_credit_limit', 'customer_age']\n",
    "\n",
    "# Take data from columns specified in 'params'\n",
    "reg_df = data[params]\n",
    "\n",
    "# Randomly take 70 percent of indices\n",
    "i_row_train = np.random.choice(reg_df.shape[0], reg_df.shape[0] * 70 // 100, replace=False)\n",
    "\n",
    "# 'fraud_bool' column as target\n",
    "target_sample = reg_df.values[i_row_train, 0]\n",
    "train_sample = reg_df.values[i_row_train, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = LogisticRegressionClassifier()\n",
    "clf_nb = NaiveBayesClassifier()\n",
    "clf_knn = KNearestNeighborsClassifier()\n",
    "\n",
    "clf_log.fit(train_sample, target_sample)\n",
    "clf_nb.fit(train_sample, target_sample)\n",
    "clf_knn.fit(tf.transform(train_sample), target_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test ####\n",
    "# Fraud\n",
    "test = pd.DataFrame([\n",
    "       {\n",
    "           'device_os_windows' : 1,\n",
    "           'credit_risk_score' : 350,\n",
    "           'proposed_credit_limit' : 1500,\n",
    "           'customer_age' : 50\n",
    "       }])\n",
    "\n",
    "print(test)\n",
    "\n",
    "clf_knn.predict(tf.transform(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
